# RAPTOR Implementation Plan

**Created:** 2025-10-17
**Agent:** Type Safety Guardian
**Phase:** RAG Phase 2 - Hierarchical Retrieval

---

## Overview

Complete TypeScript design for RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval) hierarchical document clustering and retrieval system.

---

## 1. TypeScript Interface Definitions

### 1.1 Core Types (`lib/retrieval/hierarchical/types.ts`)

```typescript
import type { CourseMaterial, CourseMaterialType } from "@/lib/models/types";
import type { Embedding } from "@/lib/retrieval/types";

/**
 * Document node in the hierarchy tree
 *
 * Represents either a raw document (leaf) or a cluster summary (internal node).
 * Each node stores content, embedding, and pointers to children/parent.
 */
export interface DocumentNode {
  /** Unique node identifier */
  id: string;

  /** Hierarchy level (0 = leaf/raw docs, 1+ = summaries) */
  level: number;

  /** Node content (raw doc text or summary text) */
  content: string;

  /** Summary of this node's content (may be same as content for leaves) */
  summary: string;

  /** Embedding vector for retrieval */
  embedding: Embedding;

  /** Child nodes (empty for leaf nodes) */
  children: DocumentNode[];

  /** Parent node (null for root) */
  parent: DocumentNode | null;

  /** Original material IDs that contributed to this node */
  materialIds: string[];

  /** Node metadata */
  metadata: {
    /** Material type (for leaves) */
    type?: CourseMaterialType;

    /** Node title (for display) */
    title: string;

    /** Coherence score (0-100) */
    coherenceScore?: number;

    /** Number of tokens in content */
    tokenCount: number;

    /** Timestamp when node was created */
    createdAt: string;
  };
}

/**
 * Document cluster with members and summary
 *
 * Intermediate structure used during hierarchy construction.
 * Represents a group of similar documents/nodes.
 */
export interface DocumentCluster {
  /** Unique cluster identifier */
  id: string;

  /** Cluster members (nodes being clustered) */
  members: DocumentNode[];

  /** Centroid embedding (mean of member embeddings) */
  centroid: Embedding;

  /** Cluster summary text (generated by LLM) */
  summary: string;

  /** Coherence score (0-100, higher = better) */
  coherenceScore: number;

  /** Cluster metadata */
  metadata: {
    /** Average similarity within cluster */
    intraClusterSimilarity: number;

    /** Size (number of members) */
    size: number;

    /** Level in hierarchy */
    level: number;
  };
}

/**
 * Complete hierarchy tree for a course
 *
 * Root structure containing all levels of the document hierarchy.
 * Supports efficient multi-level retrieval.
 */
export interface HierarchyTree {
  /** Course ID this hierarchy belongs to */
  courseId: string;

  /** Root node (top-level summary) */
  root: DocumentNode;

  /** Nodes organized by level (0 = leaves, 1+ = summaries) */
  levels: DocumentNode[][];

  /** Index for fast lookup by material ID */
  materialIndex: Map<string, DocumentNode>;

  /** Metadata about the hierarchy */
  metadata: {
    /** Number of raw documents (level 0) */
    documentCount: number;

    /** Number of levels in hierarchy */
    levelCount: number;

    /** Average coherence score across all summaries */
    avgCoherence: number;

    /** Timestamp when hierarchy was built */
    builtAt: string;

    /** Total construction time in ms */
    constructionTime: number;
  };
}

/**
 * Configuration for clustering algorithm
 */
export interface ClusteringConfig {
  /** Clustering algorithm type */
  algorithm: "hierarchical" | "kmeans";

  /** Distance metric for clustering */
  distanceMetric: "cosine" | "euclidean";

  /** Linkage method (hierarchical only) */
  linkageMethod?: "average" | "complete" | "single" | "ward";

  /** Number of clusters (kmeans only, hierarchical uses threshold) */
  k?: number;

  /** Distance threshold for stopping (hierarchical only) */
  distanceThreshold?: number;

  /** Minimum cluster size (avoid singleton clusters) */
  minClusterSize: number;

  /** Maximum cluster size (avoid giant clusters) */
  maxClusterSize: number;
}

/**
 * Configuration for summarization
 */
export interface SummarizerConfig {
  /** Maximum input tokens for LLM */
  maxInputTokens: number;

  /** Maximum output tokens for summary */
  maxOutputTokens: number;

  /** LLM provider to use */
  provider: "anthropic" | "openai";

  /** LLM model name */
  model: string;

  /** Temperature for generation (0-1) */
  temperature: number;

  /** Enable prompt caching (Anthropic) */
  enableCaching: boolean;

  /** Minimum coherence score to accept summary */
  minCoherenceScore: number;

  /** Batch size for parallel summarization */
  batchSize: number;
}

/**
 * Configuration for hierarchy traversal
 */
export interface TraversalConfig {
  /** Traversal strategy */
  strategy: "top-down" | "bottom-up" | "hybrid";

  /** Maximum number of nodes to return */
  maxNodes: number;

  /** Top-K nodes to explore per level */
  topKPerLevel: number;

  /** Minimum relevance score to include node */
  minRelevanceScore: number;

  /** Maximum depth to traverse (null = unlimited) */
  maxDepth: number | null;

  /** Whether to deduplicate by material ID */
  deduplicateResults: boolean;
}

/**
 * Hierarchy construction options
 */
export interface HierarchyConstructionOptions {
  clustering: ClusteringConfig;
  summarization: SummarizerConfig;
  traversal: TraversalConfig;
}

/**
 * Retrieval result from hierarchy
 */
export interface HierarchyRetrievalResult {
  /** Retrieved node */
  node: DocumentNode;

  /** Relevance score (0-1) */
  relevanceScore: number;

  /** Level where node was found */
  level: number;

  /** Path from root to this node */
  path: DocumentNode[];

  /** Original materials contributing to this node */
  materials: CourseMaterial[];
}

/**
 * Metrics for hierarchy construction
 */
export interface ConstructionMetrics {
  /** Time spent clustering (ms) */
  clusteringTime: number;

  /** Time spent generating summaries (ms) */
  summarizationTime: number;

  /** Time spent computing embeddings (ms) */
  embeddingTime: number;

  /** Total construction time (ms) */
  totalTime: number;

  /** Number of LLM calls made */
  llmCallCount: number;

  /** Total tokens used (input + output) */
  totalTokens: number;

  /** Estimated cost in USD */
  estimatedCost: number;

  /** Number of clusters per level */
  clustersPerLevel: number[];

  /** Average coherence per level */
  avgCoherencePerLevel: number[];
}

/**
 * Metrics for hierarchy traversal
 */
export interface TraversalMetrics {
  /** Time spent traversing (ms) */
  traversalTime: number;

  /** Number of nodes visited */
  nodesVisited: number;

  /** Number of nodes scored */
  nodesScored: number;

  /** Depth reached in traversal */
  depthReached: number;

  /** Number of results returned */
  resultsCount: number;
}
```

---

## 2. DocumentClusterer Class Design

### 2.1 Class Structure (`lib/retrieval/hierarchical/DocumentClusterer.ts`)

```typescript
import type {
  DocumentNode,
  DocumentCluster,
  ClusteringConfig,
} from "./types";
import type { Embedding } from "@/lib/retrieval/types";

/**
 * Document Clusterer
 *
 * Clusters documents using hierarchical or k-means clustering.
 * Produces balanced clusters suitable for summarization.
 */
export class DocumentClusterer {
  private config: Required<ClusteringConfig>;

  constructor(config?: Partial<ClusteringConfig>) {
    // Defaults optimized for small course corpora
    this.config = {
      algorithm: config?.algorithm ?? "hierarchical",
      distanceMetric: config?.distanceMetric ?? "cosine",
      linkageMethod: config?.linkageMethod ?? "average",
      k: config?.k ?? undefined,
      distanceThreshold: config?.distanceThreshold ?? 0.5,
      minClusterSize: config?.minClusterSize ?? 2,
      maxClusterSize: config?.maxClusterSize ?? 7,
    };
  }

  /**
   * Cluster documents into groups
   *
   * @param nodes - Nodes to cluster
   * @returns Array of clusters
   */
  async cluster(nodes: DocumentNode[]): Promise<DocumentCluster[]> {
    if (nodes.length === 0) {
      return [];
    }

    // Single node â†’ single cluster
    if (nodes.length === 1) {
      return [this.createSingletonCluster(nodes[0])];
    }

    // Choose algorithm
    if (this.config.algorithm === "hierarchical") {
      return this.hierarchicalClustering(nodes);
    } else {
      return this.kMeansClustering(nodes);
    }
  }

  /**
   * Hierarchical agglomerative clustering
   *
   * Uses average linkage for balanced clusters.
   * Stops when distance threshold exceeded.
   */
  private async hierarchicalClustering(
    nodes: DocumentNode[]
  ): Promise<DocumentCluster[]> {
    // Initialize: each node is its own cluster
    const clusters: DocumentCluster[] = nodes.map(node =>
      this.createSingletonCluster(node)
    );

    // Compute distance matrix (all pairs)
    const distances = this.computeDistanceMatrix(clusters);

    // Merge until threshold or min clusters reached
    while (clusters.length > 1) {
      // Find closest pair
      const { i, j, distance } = this.findClosestPair(clusters, distances);

      // Check stopping criteria
      if (distance > this.config.distanceThreshold) {
        break; // Too dissimilar
      }

      if (
        clusters[i].members.length + clusters[j].members.length >
        this.config.maxClusterSize
      ) {
        break; // Would create too large cluster
      }

      // Merge clusters
      const merged = this.mergeClusters(clusters[i], clusters[j]);

      // Update clusters array
      clusters.splice(Math.max(i, j), 1); // Remove j
      clusters.splice(Math.min(i, j), 1); // Remove i
      clusters.push(merged);

      // Update distance matrix
      this.updateDistanceMatrix(distances, clusters, merged);
    }

    return clusters;
  }

  /**
   * K-means clustering
   *
   * Requires k to be specified upfront.
   * Uses k-means++ initialization.
   */
  private async kMeansClustering(
    nodes: DocumentNode[]
  ): Promise<DocumentCluster[]> {
    const k = this.config.k ?? this.estimateK(nodes.length);

    // Initialize centroids using k-means++
    const centroids = this.initializeCentroidsKMeansPlusPlus(nodes, k);

    let assignments: number[] = [];
    let converged = false;
    let iterations = 0;
    const maxIterations = 100;

    // Iterate until convergence
    while (!converged && iterations < maxIterations) {
      // Assign nodes to nearest centroid
      const newAssignments = nodes.map(node =>
        this.findNearestCentroid(node, centroids)
      );

      // Check convergence
      converged =
        iterations > 0 &&
        newAssignments.every((a, i) => a === assignments[i]);

      assignments = newAssignments;

      // Recompute centroids
      for (let i = 0; i < k; i++) {
        const clusterNodes = nodes.filter((_, idx) => assignments[idx] === i);
        if (clusterNodes.length > 0) {
          centroids[i] = this.computeCentroid(clusterNodes);
        }
      }

      iterations++;
    }

    // Build clusters from final assignments
    const clusters: DocumentCluster[] = [];
    for (let i = 0; i < k; i++) {
      const members = nodes.filter((_, idx) => assignments[idx] === i);
      if (members.length >= this.config.minClusterSize) {
        clusters.push(this.createCluster(members, centroids[i]));
      }
    }

    return clusters;
  }

  /**
   * Calculate similarity between two embeddings
   */
  calculateSimilarity(
    embedding1: Embedding,
    embedding2: Embedding
  ): number {
    if (this.config.distanceMetric === "cosine") {
      return this.cosineSimilarity(embedding1.vector, embedding2.vector);
    } else {
      return 1 / (1 + this.euclideanDistance(embedding1.vector, embedding2.vector));
    }
  }

  /**
   * Compute centroid of a cluster
   */
  private computeCentroid(nodes: DocumentNode[]): Embedding {
    const dim = nodes[0].embedding.dimensions;
    const centroid = new Array(dim).fill(0);

    // Average all embeddings
    for (const node of nodes) {
      for (let i = 0; i < dim; i++) {
        centroid[i] += node.embedding.vector[i];
      }
    }

    for (let i = 0; i < dim; i++) {
      centroid[i] /= nodes.length;
    }

    // Normalize (for cosine similarity)
    const norm = Math.sqrt(centroid.reduce((sum, val) => sum + val * val, 0));
    for (let i = 0; i < dim; i++) {
      centroid[i] /= norm;
    }

    return {
      vector: centroid,
      dimensions: dim,
    };
  }

  /**
   * Cosine similarity (0-1, higher = more similar)
   */
  private cosineSimilarity(vec1: number[], vec2: number[]): number {
    let dot = 0;
    let norm1 = 0;
    let norm2 = 0;

    for (let i = 0; i < vec1.length; i++) {
      dot += vec1[i] * vec2[i];
      norm1 += vec1[i] * vec1[i];
      norm2 += vec2[i] * vec2[i];
    }

    const denominator = Math.sqrt(norm1) * Math.sqrt(norm2);
    return denominator === 0 ? 0 : dot / denominator;
  }

  /**
   * Euclidean distance (lower = more similar)
   */
  private euclideanDistance(vec1: number[], vec2: number[]): number {
    let sum = 0;
    for (let i = 0; i < vec1.length; i++) {
      const diff = vec1[i] - vec2[i];
      sum += diff * diff;
    }
    return Math.sqrt(sum);
  }

  /**
   * Estimate optimal K for k-means using square root rule
   */
  private estimateK(n: number): number {
    // Rule of thumb: k â‰ˆ sqrt(n/2)
    return Math.max(2, Math.min(10, Math.ceil(Math.sqrt(n / 2))));
  }

  /**
   * Create cluster from single node
   */
  private createSingletonCluster(node: DocumentNode): DocumentCluster {
    return {
      id: `cluster-${node.id}`,
      members: [node],
      centroid: node.embedding,
      summary: node.content,
      coherenceScore: 100, // Perfect coherence (single doc)
      metadata: {
        intraClusterSimilarity: 1.0,
        size: 1,
        level: node.level,
      },
    };
  }

  /**
   * Create cluster from multiple nodes
   */
  private createCluster(
    members: DocumentNode[],
    centroid: Embedding
  ): DocumentCluster {
    const similarity = this.calculateIntraClusterSimilarity(members);

    return {
      id: `cluster-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
      members,
      centroid,
      summary: "", // Will be filled by summarizer
      coherenceScore: 0, // Will be computed after summarization
      metadata: {
        intraClusterSimilarity: similarity,
        size: members.length,
        level: members[0].level,
      },
    };
  }

  /**
   * Calculate average pairwise similarity within cluster
   */
  private calculateIntraClusterSimilarity(nodes: DocumentNode[]): number {
    if (nodes.length < 2) return 1.0;

    let sum = 0;
    let count = 0;

    for (let i = 0; i < nodes.length; i++) {
      for (let j = i + 1; j < nodes.length; j++) {
        sum += this.calculateSimilarity(
          nodes[i].embedding,
          nodes[j].embedding
        );
        count++;
      }
    }

    return count > 0 ? sum / count : 0;
  }

  /**
   * Compute distance matrix for all cluster pairs
   */
  private computeDistanceMatrix(
    clusters: DocumentCluster[]
  ): Map<string, number> {
    const distances = new Map<string, number>();

    for (let i = 0; i < clusters.length; i++) {
      for (let j = i + 1; j < clusters.length; j++) {
        const distance =
          1 -
          this.calculateSimilarity(clusters[i].centroid, clusters[j].centroid);
        const key = `${i}-${j}`;
        distances.set(key, distance);
      }
    }

    return distances;
  }

  /**
   * Find closest pair of clusters
   */
  private findClosestPair(
    clusters: DocumentCluster[],
    distances: Map<string, number>
  ): { i: number; j: number; distance: number } {
    let minDistance = Infinity;
    let minI = 0;
    let minJ = 1;

    for (let i = 0; i < clusters.length; i++) {
      for (let j = i + 1; j < clusters.length; j++) {
        const key = `${i}-${j}`;
        const distance = distances.get(key) ?? Infinity;

        if (distance < minDistance) {
          minDistance = distance;
          minI = i;
          minJ = j;
        }
      }
    }

    return { i: minI, j: minJ, distance: minDistance };
  }

  /**
   * Merge two clusters
   */
  private mergeClusters(
    cluster1: DocumentCluster,
    cluster2: DocumentCluster
  ): DocumentCluster {
    const members = [...cluster1.members, ...cluster2.members];
    const centroid = this.computeCentroid(members);
    return this.createCluster(members, centroid);
  }

  /**
   * Update distance matrix after merge
   */
  private updateDistanceMatrix(
    distances: Map<string, number>,
    clusters: DocumentCluster[],
    merged: DocumentCluster
  ): void {
    // Recompute distances involving the merged cluster
    const mergedIdx = clusters.length - 1;

    for (let i = 0; i < mergedIdx; i++) {
      const distance =
        1 - this.calculateSimilarity(clusters[i].centroid, merged.centroid);
      distances.set(`${i}-${mergedIdx}`, distance);
    }
  }

  /**
   * Find nearest centroid for a node (k-means)
   */
  private findNearestCentroid(
    node: DocumentNode,
    centroids: Embedding[]
  ): number {
    let maxSimilarity = -Infinity;
    let nearestIdx = 0;

    for (let i = 0; i < centroids.length; i++) {
      const similarity = this.calculateSimilarity(node.embedding, centroids[i]);
      if (similarity > maxSimilarity) {
        maxSimilarity = similarity;
        nearestIdx = i;
      }
    }

    return nearestIdx;
  }

  /**
   * Initialize centroids using k-means++ algorithm
   */
  private initializeCentroidsKMeansPlusPlus(
    nodes: DocumentNode[],
    k: number
  ): Embedding[] {
    const centroids: Embedding[] = [];

    // First centroid: random node
    const firstIdx = Math.floor(Math.random() * nodes.length);
    centroids.push(nodes[firstIdx].embedding);

    // Remaining centroids: weighted by distance
    for (let i = 1; i < k; i++) {
      const distances = nodes.map(node => {
        // Min distance to any existing centroid
        return Math.min(
          ...centroids.map(c => 1 - this.calculateSimilarity(node.embedding, c))
        );
      });

      // Probability proportional to distance squared
      const probabilities = distances.map(d => d * d);
      const sum = probabilities.reduce((a, b) => a + b, 0);
      const normalized = probabilities.map(p => p / sum);

      // Select next centroid using weighted random
      let rand = Math.random();
      let idx = 0;
      for (let j = 0; j < normalized.length; j++) {
        rand -= normalized[j];
        if (rand <= 0) {
          idx = j;
          break;
        }
      }

      centroids.push(nodes[idx].embedding);
    }

    return centroids;
  }

  /**
   * Get configuration
   */
  getConfig(): ClusteringConfig {
    return this.config;
  }

  /**
   * Update configuration
   */
  setConfig(config: Partial<ClusteringConfig>): void {
    this.config = {
      ...this.config,
      ...config,
    } as Required<ClusteringConfig>;
  }
}
```

---

## 3. HierarchySummarizer Class Design

### 3.1 Class Structure (`lib/retrieval/hierarchical/HierarchySummarizer.ts`)

```typescript
import type { DocumentCluster, SummarizerConfig } from "./types";
import type { LLMProviderType } from "@/lib/models/types";
import { AnthropicProvider } from "@/lib/llm/providers/AnthropicProvider";
import { OpenAIProvider } from "@/lib/llm/providers/OpenAIProvider";

/**
 * Hierarchy Summarizer
 *
 * Generates abstractive summaries for document clusters using LLM.
 * Supports batching and prompt caching for efficiency.
 */
export class HierarchySummarizer {
  private config: Required<SummarizerConfig>;
  private llmProvider: AnthropicProvider | OpenAIProvider;
  private summaryCache: Map<string, string>;

  constructor(config?: Partial<SummarizerConfig>) {
    this.config = {
      maxInputTokens: config?.maxInputTokens ?? 8000,
      maxOutputTokens: config?.maxOutputTokens ?? 500,
      provider: config?.provider ?? "anthropic",
      model: config?.model ?? "claude-3-5-sonnet-20241022",
      temperature: config?.temperature ?? 0.3,
      enableCaching: config?.enableCaching ?? true,
      minCoherenceScore: config?.minCoherenceScore ?? 0.7,
      batchSize: config?.batchSize ?? 5,
    };

    // Initialize LLM provider
    this.llmProvider =
      this.config.provider === "anthropic"
        ? new AnthropicProvider()
        : new OpenAIProvider();

    this.summaryCache = new Map();
  }

  /**
   * Summarize a single cluster
   *
   * @param cluster - Cluster to summarize
   * @param courseContext - Course metadata for context
   * @returns Summary text
   */
  async summarize(
    cluster: DocumentCluster,
    courseContext: {
      courseName: string;
      courseCode: string;
    }
  ): Promise<string> {
    // Check cache first
    const cacheKey = this.getCacheKey(cluster);
    const cached = this.summaryCache.get(cacheKey);
    if (cached) {
      console.log(`[HierarchySummarizer] Cache hit for cluster ${cluster.id}`);
      return cached;
    }

    // Build prompt
    const prompt = this.buildSummaryPrompt(cluster, courseContext);

    // Call LLM
    const response = await this.llmProvider.generate({
      systemPrompt: this.buildSystemPrompt(courseContext),
      userPrompt: prompt,
      maxTokens: this.config.maxOutputTokens,
      temperature: this.config.temperature,
      enableCaching: this.config.enableCaching,
    });

    if (!response.success) {
      console.error(`[HierarchySummarizer] LLM error:`, response.error);
      // Fallback: concatenate titles
      return this.extractiveFallback(cluster);
    }

    const summary = response.content.trim();

    // Validate coherence
    const coherence = await this.validateCoherence(summary, cluster);

    if (coherence < this.config.minCoherenceScore) {
      console.warn(
        `[HierarchySummarizer] Low coherence (${coherence.toFixed(2)}) for cluster ${cluster.id}, using fallback`
      );
      return this.extractiveFallback(cluster);
    }

    // Cache and return
    this.summaryCache.set(cacheKey, summary);
    return summary;
  }

  /**
   * Summarize multiple clusters in batch
   *
   * @param clusters - Clusters to summarize
   * @param courseContext - Course metadata
   * @returns Array of summaries (same order as input)
   */
  async summarizeBatch(
    clusters: DocumentCluster[],
    courseContext: {
      courseName: string;
      courseCode: string;
    }
  ): Promise<string[]> {
    const summaries: string[] = [];

    // Process in batches
    for (let i = 0; i < clusters.length; i += this.config.batchSize) {
      const batch = clusters.slice(i, i + this.config.batchSize);

      // Parallel summarization within batch
      const batchSummaries = await Promise.all(
        batch.map(cluster => this.summarize(cluster, courseContext))
      );

      summaries.push(...batchSummaries);
    }

    return summaries;
  }

  /**
   * Validate coherence of summary
   *
   * Checks if summary is semantically similar to cluster centroid.
   * Uses embedding similarity as proxy for coherence.
   *
   * @param summary - Generated summary
   * @param cluster - Original cluster
   * @returns Coherence score (0-1)
   */
  async validateCoherence(
    summary: string,
    cluster: DocumentCluster
  ): Promise<number> {
    // Embed summary
    const summaryEmbedding = await this.embedText(summary);

    // Compare to cluster centroid
    const similarity = this.cosineSimilarity(
      summaryEmbedding.vector,
      cluster.centroid.vector
    );

    return similarity;
  }

  /**
   * Trim summary to token limit
   *
   * Ensures summary doesn't exceed maxOutputTokens.
   * Uses simple token estimation (chars / 4).
   */
  trimToTokenLimit(summary: string): string {
    const estimatedTokens = summary.length / 4;

    if (estimatedTokens <= this.config.maxOutputTokens) {
      return summary;
    }

    // Trim to approximate token limit
    const maxChars = this.config.maxOutputTokens * 4;
    return summary.substring(0, maxChars) + "...";
  }

  /**
   * Build system prompt for LLM
   */
  private buildSystemPrompt(courseContext: {
    courseName: string;
    courseCode: string;
  }): string {
    return `You are an expert educational content summarizer for ${courseContext.courseCode}: ${courseContext.courseName}.

Your task is to create cohesive, accurate summaries of course materials that:
1. Capture the main themes and key concepts
2. Show relationships between materials
3. Maintain technical accuracy
4. Use clear, educational language
5. Stay within 200-400 words

Focus on what students need to understand, not just listing topics.`;
  }

  /**
   * Build summary prompt for specific cluster
   */
  private buildSummaryPrompt(
    cluster: DocumentCluster,
    courseContext: {
      courseName: string;
      courseCode: string;
    }
  ): string {
    const materials = cluster.members
      .map((node, idx) => {
        const title = node.metadata.title;
        const excerpt = this.extractExcerpt(node.content, 300);
        return `${idx + 1}. ${title}\n${excerpt}\n`;
      })
      .join("\n");

    return `Summarize the following ${cluster.members.length} course materials into a cohesive overview.

Course: ${courseContext.courseCode} - ${courseContext.courseName}
Level: ${cluster.metadata.level === 0 ? "Raw Documents" : `Summary Level ${cluster.metadata.level}`}

Materials:
${materials}

Generate a comprehensive summary (200-400 words) that:
- Identifies main themes and concepts
- Shows how materials relate to each other
- Maintains technical accuracy
- Uses clear educational language

Summary:`;
  }

  /**
   * Extract excerpt from content
   */
  private extractExcerpt(content: string, maxChars: number): string {
    if (content.length <= maxChars) {
      return content;
    }

    // Find sentence boundary near maxChars
    const truncated = content.substring(0, maxChars);
    const lastPeriod = truncated.lastIndexOf(".");
    const lastNewline = truncated.lastIndexOf("\n");
    const cutoff = Math.max(lastPeriod, lastNewline);

    return cutoff > 0
      ? truncated.substring(0, cutoff + 1)
      : truncated + "...";
  }

  /**
   * Extractive fallback (when LLM fails)
   *
   * Concatenates key sentences from each document.
   */
  private extractiveFallback(cluster: DocumentCluster): string {
    const excerpts = cluster.members.map(node => {
      const title = node.metadata.title;
      const firstSentence = node.content.split(".")[0] + ".";
      return `${title}: ${firstSentence}`;
    });

    return excerpts.join(" ");
  }

  /**
   * Generate cache key for cluster
   */
  private getCacheKey(cluster: DocumentCluster): string {
    // Hash based on member IDs
    const ids = cluster.members.map(m => m.id).sort().join(",");
    return `${cluster.id}-${ids}`;
  }

  /**
   * Embed text using vector store
   */
  private async embedText(text: string): Promise<{ vector: number[] }> {
    // Delegate to vector store's embedding function
    // (Implementation depends on your embedding provider)
    const { EmbeddingRetriever } = await import("@/lib/retrieval/EmbeddingRetriever");
    const embedder = new EmbeddingRetriever([]);
    return embedder["embedText"](text); // Access private method for reuse
  }

  /**
   * Cosine similarity
   */
  private cosineSimilarity(vec1: number[], vec2: number[]): number {
    let dot = 0;
    let norm1 = 0;
    let norm2 = 0;

    for (let i = 0; i < vec1.length; i++) {
      dot += vec1[i] * vec2[i];
      norm1 += vec1[i] * vec1[i];
      norm2 += vec2[i] * vec2[i];
    }

    const denominator = Math.sqrt(norm1) * Math.sqrt(norm2);
    return denominator === 0 ? 0 : dot / denominator;
  }

  /**
   * Clear cache
   */
  clearCache(): void {
    this.summaryCache.clear();
  }

  /**
   * Get configuration
   */
  getConfig(): SummarizerConfig {
    return this.config;
  }

  /**
   * Update configuration
   */
  setConfig(config: Partial<SummarizerConfig>): void {
    this.config = {
      ...this.config,
      ...config,
    } as Required<SummarizerConfig>;
  }
}
```

---

## 4. HierarchyTraverser Class Design

### 4.1 Class Structure (`lib/retrieval/hierarchical/HierarchyTraverser.ts`)

```typescript
import type {
  HierarchyTree,
  DocumentNode,
  TraversalConfig,
  HierarchyRetrievalResult,
  TraversalMetrics,
} from "./types";
import type { Embedding } from "@/lib/retrieval/types";
import type { CourseMaterial } from "@/lib/models/types";

/**
 * Hierarchy Traverser
 *
 * Traverses the hierarchy tree to find relevant nodes for a query.
 * Supports multiple traversal strategies (top-down, bottom-up, hybrid).
 */
export class HierarchyTraverser {
  private config: Required<TraversalConfig>;
  private materials: Map<string, CourseMaterial>;

  constructor(
    materials: CourseMaterial[],
    config?: Partial<TraversalConfig>
  ) {
    this.config = {
      strategy: config?.strategy ?? "top-down",
      maxNodes: config?.maxNodes ?? 10,
      topKPerLevel: config?.topKPerLevel ?? 3,
      minRelevanceScore: config?.minRelevanceScore ?? 0.6,
      maxDepth: config?.maxDepth ?? null,
      deduplicateResults: config?.deduplicateResults ?? true,
    };

    // Build material index
    this.materials = new Map(materials.map(m => [m.id, m]));
  }

  /**
   * Traverse hierarchy to find relevant nodes
   *
   * @param query - Query embedding
   * @param tree - Hierarchy tree
   * @returns Sorted retrieval results
   */
  async traverse(
    query: Embedding,
    tree: HierarchyTree
  ): Promise<HierarchyRetrievalResult[]> {
    const startTime = performance.now();
    const metrics: Partial<TraversalMetrics> = {
      nodesVisited: 0,
      nodesScored: 0,
      depthReached: 0,
    };

    try {
      let results: HierarchyRetrievalResult[];

      // Choose strategy
      switch (this.config.strategy) {
        case "top-down":
          results = await this.topDownTraversal(query, tree, metrics);
          break;
        case "bottom-up":
          results = await this.bottomUpTraversal(query, tree, metrics);
          break;
        case "hybrid":
          results = await this.hybridTraversal(query, tree, metrics);
          break;
        default:
          throw new Error(`Unknown traversal strategy: ${this.config.strategy}`);
      }

      // Deduplicate if enabled
      if (this.config.deduplicateResults) {
        results = this.deduplicateByMaterial(results);
      }

      // Limit results
      results = results.slice(0, this.config.maxNodes);

      metrics.resultsCount = results.length;
      metrics.traversalTime = performance.now() - startTime;

      console.log(
        `[HierarchyTraverser] Strategy: ${this.config.strategy} | ` +
          `Visited: ${metrics.nodesVisited} | Scored: ${metrics.nodesScored} | ` +
          `Results: ${results.length} | Time: ${metrics.traversalTime?.toFixed(2)}ms`
      );

      return results;
    } catch (error) {
      console.error(`[HierarchyTraverser] Error during traversal:`, error);
      throw error;
    }
  }

  /**
   * Top-down breadth-first traversal
   *
   * Start at root, explore most relevant branches first.
   * Prunes irrelevant subtrees early.
   */
  private async topDownTraversal(
    query: Embedding,
    tree: HierarchyTree,
    metrics: Partial<TraversalMetrics>
  ): Promise<HierarchyRetrievalResult[]> {
    const results: HierarchyRetrievalResult[] = [];
    const queue: { node: DocumentNode; path: DocumentNode[] }[] = [
      { node: tree.root, path: [] },
    ];

    let currentDepth = 0;

    while (queue.length > 0 && results.length < this.config.maxNodes) {
      // Check depth limit
      if (this.config.maxDepth !== null && currentDepth >= this.config.maxDepth) {
        break;
      }

      // Process current level
      const levelSize = queue.length;
      const levelNodes: {
        node: DocumentNode;
        score: number;
        path: DocumentNode[];
      }[] = [];

      for (let i = 0; i < levelSize; i++) {
        const { node, path } = queue.shift()!;
        metrics.nodesVisited = (metrics.nodesVisited ?? 0) + 1;

        // Score node
        const score = this.scoreNode(query, node);
        metrics.nodesScored = (metrics.nodesScored ?? 0) + 1;

        if (score >= this.config.minRelevanceScore) {
          levelNodes.push({ node, score, path: [...path, node] });
        }
      }

      // Sort by score
      levelNodes.sort((a, b) => b.score - a.score);

      // Select top-K nodes
      const selected = levelNodes.slice(0, this.config.topKPerLevel);

      // Add to results and queue children
      for (const { node, score, path } of selected) {
        results.push(this.createResult(node, score, path));

        // Queue children for next level
        for (const child of node.children) {
          queue.push({ node: child, path });
        }
      }

      currentDepth++;
      metrics.depthReached = currentDepth;
    }

    return results.sort((a, b) => b.relevanceScore - a.relevanceScore);
  }

  /**
   * Bottom-up traversal
   *
   * Start at leaves (raw documents), walk up to ancestors.
   * Good for specific queries needing detailed information.
   */
  private async bottomUpTraversal(
    query: Embedding,
    tree: HierarchyTree,
    metrics: Partial<TraversalMetrics>
  ): Promise<HierarchyRetrievalResult[]> {
    const results: HierarchyRetrievalResult[] = [];

    // Get leaf nodes (level 0)
    const leaves = tree.levels[0] ?? [];

    // Score all leaves
    const scoredLeaves = leaves.map(node => ({
      node,
      score: this.scoreNode(query, node),
    }));

    metrics.nodesScored = (metrics.nodesScored ?? 0) + leaves.length;

    // Sort by score
    scoredLeaves.sort((a, b) => b.score - a.score);

    // Select top leaves
    const topLeaves = scoredLeaves
      .filter(({ score }) => score >= this.config.minRelevanceScore)
      .slice(0, this.config.maxNodes);

    // Add leaves and their ancestors
    const visited = new Set<string>();

    for (const { node, score } of topLeaves) {
      if (results.length >= this.config.maxNodes) break;

      // Add leaf
      if (!visited.has(node.id)) {
        results.push(this.createResult(node, score, [node]));
        visited.add(node.id);
        metrics.nodesVisited = (metrics.nodesVisited ?? 0) + 1;
      }

      // Walk up ancestors
      let current = node.parent;
      const path: DocumentNode[] = [node];

      while (current && results.length < this.config.maxNodes * 1.5) {
        path.push(current);

        if (!visited.has(current.id)) {
          const ancestorScore = this.scoreNode(query, current);
          metrics.nodesScored = (metrics.nodesScored ?? 0) + 1;

          if (ancestorScore >= this.config.minRelevanceScore) {
            results.push(this.createResult(current, ancestorScore, [...path].reverse()));
            visited.add(current.id);
            metrics.nodesVisited = (metrics.nodesVisited ?? 0) + 1;
          }
        }

        current = current.parent;
      }
    }

    return results.sort((a, b) => b.relevanceScore - a.relevanceScore);
  }

  /**
   * Hybrid traversal
   *
   * Combines top-down and bottom-up strategies.
   * Allocates half the budget to each approach.
   */
  private async hybridTraversal(
    query: Embedding,
    tree: HierarchyTree,
    metrics: Partial<TraversalMetrics>
  ): Promise<HierarchyRetrievalResult[]> {
    const halfBudget = Math.ceil(this.config.maxNodes / 2);

    // Save original config
    const originalMaxNodes = this.config.maxNodes;

    // Top-down pass (half budget)
    this.config.maxNodes = halfBudget;
    const topDownResults = await this.topDownTraversal(query, tree, metrics);

    // Bottom-up pass (half budget)
    const bottomUpResults = await this.bottomUpTraversal(query, tree, metrics);

    // Restore config
    this.config.maxNodes = originalMaxNodes;

    // Merge and deduplicate
    const merged = [...topDownResults, ...bottomUpResults];
    const deduplicated = this.deduplicateByNode(merged);

    // Rerank by combined score
    return deduplicated
      .sort((a, b) => b.relevanceScore - a.relevanceScore)
      .slice(0, this.config.maxNodes);
  }

  /**
   * Score a node's relevance to query
   */
  private scoreNode(query: Embedding, node: DocumentNode): number {
    return this.cosineSimilarity(query.vector, node.embedding.vector);
  }

  /**
   * Create retrieval result from node
   */
  private createResult(
    node: DocumentNode,
    score: number,
    path: DocumentNode[]
  ): HierarchyRetrievalResult {
    // Resolve materials from IDs
    const materials = node.materialIds
      .map(id => this.materials.get(id))
      .filter((m): m is CourseMaterial => m !== undefined);

    return {
      node,
      relevanceScore: score,
      level: node.level,
      path,
      materials,
    };
  }

  /**
   * Deduplicate results by node ID
   */
  private deduplicateByNode(
    results: HierarchyRetrievalResult[]
  ): HierarchyRetrievalResult[] {
    const seen = new Set<string>();
    return results.filter(result => {
      if (seen.has(result.node.id)) {
        return false;
      }
      seen.add(result.node.id);
      return true;
    });
  }

  /**
   * Deduplicate results by material ID (prefer higher-level summaries)
   */
  private deduplicateByMaterial(
    results: HierarchyRetrievalResult[]
  ): HierarchyRetrievalResult[] {
    const materialMap = new Map<string, HierarchyRetrievalResult>();

    for (const result of results) {
      for (const materialId of result.node.materialIds) {
        const existing = materialMap.get(materialId);

        if (!existing || result.level > existing.level) {
          // Prefer higher-level (more abstract) nodes
          materialMap.set(materialId, result);
        }
      }
    }

    return Array.from(materialMap.values());
  }

  /**
   * Cosine similarity
   */
  private cosineSimilarity(vec1: number[], vec2: number[]): number {
    let dot = 0;
    let norm1 = 0;
    let norm2 = 0;

    for (let i = 0; i < vec1.length; i++) {
      dot += vec1[i] * vec2[i];
      norm1 += vec1[i] * vec1[i];
      norm2 += vec2[i] * vec2[i];
    }

    const denominator = Math.sqrt(norm1) * Math.sqrt(norm2);
    return denominator === 0 ? 0 : dot / denominator;
  }

  /**
   * Get configuration
   */
  getConfig(): TraversalConfig {
    return this.config;
  }

  /**
   * Update configuration
   */
  setConfig(config: Partial<TraversalConfig>): void {
    this.config = {
      ...this.config,
      ...config,
    } as Required<TraversalConfig>;
  }
}
```

---

## 5. Integration Points

### 5.1 Modify `lib/retrieval/types.ts`

```typescript
// Add to existing types.ts

import type { HierarchyRetrievalResult } from "./hierarchical/types";

/**
 * Extended hybrid retrieval config with hierarchy
 */
export interface HybridRetrievalConfig {
  // ... existing fields ...

  // NEW: Hierarchy options
  useHierarchy?: boolean;           // Enable hierarchical retrieval (default: false)
  hierarchyWeight?: number;         // Weight for hierarchy results (default: 0.3)
  hierarchyStrategy?: "top-down" | "bottom-up" | "hybrid"; // Traversal strategy
}

/**
 * Extended retrieval result with hierarchy metadata
 */
export interface RetrievalResult {
  // ... existing fields ...

  // NEW: Optional hierarchy metadata
  hierarchyLevel?: number;          // Level in hierarchy (0 = leaf)
  hierarchyPath?: string[];         // Path from root to this node
}
```

### 5.2 Modify `lib/retrieval/HybridRetriever.ts`

```typescript
// Add to existing HybridRetriever.ts

import { HierarchyTraverser } from "./hierarchical/HierarchyTraverser";
import type { HierarchyTree } from "./hierarchical/types";

export class HybridRetriever implements IRetriever {
  // ... existing fields ...

  private hierarchyTraverser?: HierarchyTraverser;
  private hierarchyTree?: HierarchyTree;

  constructor(/* ... existing params ... */) {
    // ... existing initialization ...

    // Initialize hierarchy if enabled
    if (this.config.useHierarchy && this.hierarchyTree) {
      this.hierarchyTraverser = new HierarchyTraverser(this.materials, {
        strategy: this.config.hierarchyStrategy,
        maxNodes: 5, // Get 5 hierarchy results
      });
    }
  }

  async retrieve(query: string, limit: number = 10): Promise<RetrievalResult[]> {
    // ... existing retrieval logic ...

    // Add hierarchy results if enabled
    if (this.config.useHierarchy && this.hierarchyTraverser && this.hierarchyTree) {
      const queryEmbedding = await this.embedQuery(query);
      const hierarchyResults = await this.hierarchyTraverser.traverse(
        queryEmbedding,
        this.hierarchyTree
      );

      // Convert to RetrievalResult format
      const convertedHierarchyResults = hierarchyResults.map(hr => ({
        material: hr.materials[0], // Use first material as representative
        score: hr.relevanceScore * this.config.hierarchyWeight,
        hierarchyLevel: hr.level,
        hierarchyPath: hr.path.map(n => n.id),
        metadata: {
          retriever: "hierarchy",
          level: hr.level,
          path: hr.path.map(n => n.metadata.title),
        },
      }));

      // Merge with existing results
      fusedResults.push(...convertedHierarchyResults);
      fusedResults.sort((a, b) => b.score - a.score);
    }

    // ... rest of existing logic ...
  }

  /**
   * Set hierarchy tree
   */
  setHierarchyTree(tree: HierarchyTree): void {
    this.hierarchyTree = tree;

    if (this.config.useHierarchy) {
      this.hierarchyTraverser = new HierarchyTraverser(this.materials, {
        strategy: this.config.hierarchyStrategy,
        maxNodes: 5,
      });
    }
  }
}
```

### 5.3 Modify `lib/llm/context/CourseContextBuilder.ts`

```typescript
// Add hierarchy construction and usage

import { DocumentClusterer } from "@/lib/retrieval/hierarchical/DocumentClusterer";
import { HierarchySummarizer } from "@/lib/retrieval/hierarchical/HierarchySummarizer";
import { HierarchyBuilder } from "@/lib/retrieval/hierarchical/HierarchyBuilder";
import type { HierarchyTree } from "@/lib/retrieval/hierarchical/types";

export class CourseContextBuilder {
  // ... existing fields ...

  private hierarchyTrees: Map<string, HierarchyTree>;

  constructor() {
    // ... existing initialization ...

    this.hierarchyTrees = new Map();
  }

  /**
   * Build hierarchy for a course
   *
   * Pre-computes hierarchy tree for faster retrieval.
   * Should be called when materials are indexed.
   */
  async buildHierarchy(courseId: string): Promise<HierarchyTree> {
    const materials = this.materialsIndex.get(courseId) ?? [];

    if (materials.length === 0) {
      throw new Error(`No materials found for course ${courseId}`);
    }

    // Get course metadata
    const course = this.courses.find(c => c.id === courseId);
    if (!course) {
      throw new Error(`Course ${courseId} not found`);
    }

    // Build hierarchy
    const builder = new HierarchyBuilder();
    const tree = await builder.build(materials, {
      courseName: course.name,
      courseCode: course.code,
    });

    // Cache tree
    this.hierarchyTrees.set(courseId, tree);

    return tree;
  }

  /**
   * Get hierarchy tree for course
   */
  getHierarchyTree(courseId: string): HierarchyTree | undefined {
    return this.hierarchyTrees.get(courseId);
  }

  /**
   * Rebuild hierarchy if materials changed
   */
  async rebuildHierarchyIfNeeded(courseId: string): Promise<void> {
    const materials = this.materialsIndex.get(courseId) ?? [];
    const existingTree = this.hierarchyTrees.get(courseId);

    if (!existingTree || existingTree.metadata.documentCount !== materials.length) {
      console.log(`[CourseContextBuilder] Rebuilding hierarchy for course ${courseId}`);
      await this.buildHierarchy(courseId);
    }
  }
}
```

---

## 6. Implementation Order

### 6.1 Step-by-Step Plan

**Day 1: Type Definitions & Clustering**
1. Create `lib/retrieval/hierarchical/types.ts` with all interfaces
2. Implement `DocumentClusterer` class
3. Write unit tests for clustering algorithms
4. Verify hierarchical clustering produces balanced clusters

**Day 2: Summarization**
1. Implement `HierarchySummarizer` class
2. Integrate with existing LLM providers
3. Test summary generation on sample clusters
4. Validate coherence scoring

**Day 3: Traversal & Builder**
1. Implement `HierarchyTraverser` class
2. Create `HierarchyBuilder` orchestrator class (combines clusterer + summarizer)
3. Test top-down, bottom-up, hybrid traversal
4. Measure traversal performance

**Day 4: Integration**
1. Modify `HybridRetriever` to support hierarchy
2. Update `CourseContextBuilder` with hierarchy building
3. Add hierarchy pre-computation during material indexing
4. Test end-to-end retrieval with hierarchy

### 6.2 Files to Create

```
lib/retrieval/hierarchical/
â”œâ”€â”€ types.ts                    # All TypeScript interfaces
â”œâ”€â”€ DocumentClusterer.ts        # Clustering implementation
â”œâ”€â”€ HierarchySummarizer.ts      # LLM summarization
â”œâ”€â”€ HierarchyTraverser.ts       # Tree traversal
â”œâ”€â”€ HierarchyBuilder.ts         # Orchestrator class (NEW)
â””â”€â”€ index.ts                    # Public exports
```

### 6.3 Files to Modify

```
lib/retrieval/
â”œâ”€â”€ types.ts                    # Add hierarchy config options
â”œâ”€â”€ HybridRetriever.ts          # Integrate hierarchy results

lib/llm/context/
â””â”€â”€ CourseContextBuilder.ts     # Add hierarchy building

lib/models/
â””â”€â”€ types.ts                    # Add hierarchy retrieval metadata (optional)
```

---

## 7. HierarchyBuilder Orchestrator

### 7.1 Class Structure (`lib/retrieval/hierarchical/HierarchyBuilder.ts`)

```typescript
import type {
  HierarchyTree,
  DocumentNode,
  HierarchyConstructionOptions,
  ConstructionMetrics,
} from "./types";
import type { CourseMaterial } from "@/lib/models/types";
import { DocumentClusterer } from "./DocumentClusterer";
import { HierarchySummarizer } from "./HierarchySummarizer";
import { EmbeddingRetriever } from "@/lib/retrieval/EmbeddingRetriever";

/**
 * Hierarchy Builder
 *
 * Orchestrates hierarchy construction from raw documents.
 * Combines clustering, summarization, and embedding.
 */
export class HierarchyBuilder {
  private clusterer: DocumentClusterer;
  private summarizer: HierarchySummarizer;
  private embedder: EmbeddingRetriever;

  constructor(options?: Partial<HierarchyConstructionOptions>) {
    this.clusterer = new DocumentClusterer(options?.clustering);
    this.summarizer = new HierarchySummarizer(options?.summarization);
    this.embedder = new EmbeddingRetriever([]); // Empty materials, just for embedding
  }

  /**
   * Build hierarchy tree from course materials
   *
   * @param materials - Raw course materials
   * @param courseContext - Course metadata
   * @returns Complete hierarchy tree
   */
  async build(
    materials: CourseMaterial[],
    courseContext: {
      courseName: string;
      courseCode: string;
    }
  ): Promise<HierarchyTree> {
    const startTime = performance.now();
    const metrics: Partial<ConstructionMetrics> = {
      llmCallCount: 0,
      totalTokens: 0,
      estimatedCost: 0,
      clustersPerLevel: [],
      avgCoherencePerLevel: [],
    };

    console.log(
      `[HierarchyBuilder] Building hierarchy for ${courseContext.courseCode} with ${materials.length} documents`
    );

    try {
      // 1. Create leaf nodes from raw materials
      const embeddingStart = performance.now();
      const leafNodes = await this.createLeafNodes(materials);
      metrics.embeddingTime = performance.now() - embeddingStart;

      // 2. Build hierarchy levels recursively
      const levels: DocumentNode[][] = [leafNodes];
      let currentLevel = leafNodes;
      let levelIndex = 0;

      while (currentLevel.length > 1) {
        console.log(
          `[HierarchyBuilder] Building level ${levelIndex + 1} from ${currentLevel.length} nodes`
        );

        // Cluster current level
        const clusteringStart = performance.now();
        const clusters = await this.clusterer.cluster(currentLevel);
        metrics.clusteringTime =
          (metrics.clusteringTime ?? 0) + (performance.now() - clusteringStart);

        if (clusters.length === currentLevel.length) {
          // No clustering occurred (all singletons)
          console.warn(
            `[HierarchyBuilder] Clustering produced no merges at level ${levelIndex + 1}, stopping`
          );
          break;
        }

        metrics.clustersPerLevel!.push(clusters.length);

        // Summarize clusters
        const summarizationStart = performance.now();
        const summaries = await this.summarizer.summarizeBatch(
          clusters,
          courseContext
        );
        metrics.summarizationTime =
          (metrics.summarizationTime ?? 0) +
          (performance.now() - summarizationStart);
        metrics.llmCallCount! += clusters.length;

        // Create parent nodes
        const parentNodes: DocumentNode[] = [];
        let totalCoherence = 0;

        for (let i = 0; i < clusters.length; i++) {
          const cluster = clusters[i];
          const summary = summaries[i];

          // Validate coherence
          const coherence = await this.summarizer.validateCoherence(
            summary,
            cluster
          );
          totalCoherence += coherence;

          // Create parent node
          const parentNode = await this.createParentNode(
            cluster,
            summary,
            coherence,
            levelIndex + 1
          );

          // Link children to parent
          for (const child of cluster.members) {
            child.parent = parentNode;
          }

          parentNodes.push(parentNode);
        }

        metrics.avgCoherencePerLevel!.push(totalCoherence / clusters.length);

        levels.push(parentNodes);
        currentLevel = parentNodes;
        levelIndex++;

        // Safety: prevent infinite loops
        if (levelIndex > 10) {
          console.warn(
            `[HierarchyBuilder] Max depth (10) reached, stopping recursion`
          );
          break;
        }
      }

      // 3. Create root node (top summary)
      const root =
        currentLevel.length === 1
          ? currentLevel[0]
          : await this.createRootNode(currentLevel, courseContext);

      // 4. Build material index
      const materialIndex = new Map<string, DocumentNode>();
      for (const node of leafNodes) {
        for (const materialId of node.materialIds) {
          materialIndex.set(materialId, node);
        }
      }

      // 5. Compute final metrics
      metrics.totalTime = performance.now() - startTime;

      const avgCoherence =
        metrics.avgCoherencePerLevel!.reduce((a, b) => a + b, 0) /
        metrics.avgCoherencePerLevel!.length;

      const tree: HierarchyTree = {
        courseId: materials[0].courseId,
        root,
        levels,
        materialIndex,
        metadata: {
          documentCount: materials.length,
          levelCount: levels.length,
          avgCoherence,
          builtAt: new Date().toISOString(),
          constructionTime: metrics.totalTime,
        },
      };

      console.log(
        `[HierarchyBuilder] Hierarchy complete: ${levels.length} levels, ` +
          `${metrics.totalTime.toFixed(0)}ms, avg coherence: ${avgCoherence.toFixed(2)}`
      );

      return tree;
    } catch (error) {
      console.error(`[HierarchyBuilder] Error during construction:`, error);
      throw error;
    }
  }

  /**
   * Create leaf nodes from raw materials
   */
  private async createLeafNodes(
    materials: CourseMaterial[]
  ): Promise<DocumentNode[]> {
    const nodes: DocumentNode[] = [];

    for (const material of materials) {
      // Embed content
      const embedding = await this.embedder["embedText"](material.content);

      const node: DocumentNode = {
        id: `node-leaf-${material.id}`,
        level: 0,
        content: material.content,
        summary: material.content, // Leaf summary = raw content
        embedding: {
          vector: embedding.vector,
          dimensions: embedding.vector.length,
        },
        children: [],
        parent: null,
        materialIds: [material.id],
        metadata: {
          type: material.type,
          title: material.title,
          tokenCount: Math.ceil(material.content.length / 4),
          createdAt: new Date().toISOString(),
        },
      };

      nodes.push(node);
    }

    return nodes;
  }

  /**
   * Create parent node from cluster
   */
  private async createParentNode(
    cluster: DocumentCluster,
    summary: string,
    coherence: number,
    level: number
  ): Promise<DocumentNode> {
    // Embed summary
    const embedding = await this.embedder["embedText"](summary);

    // Collect all material IDs from children
    const materialIds = cluster.members.flatMap(m => m.materialIds);

    const node: DocumentNode = {
      id: `node-level${level}-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
      level,
      content: summary,
      summary,
      embedding: {
        vector: embedding.vector,
        dimensions: embedding.vector.length,
      },
      children: cluster.members,
      parent: null, // Will be set in next iteration
      materialIds,
      metadata: {
        title: `Level ${level} Summary (${cluster.members.length} items)`,
        coherenceScore: coherence * 100,
        tokenCount: Math.ceil(summary.length / 4),
        createdAt: new Date().toISOString(),
      },
    };

    return node;
  }

  /**
   * Create root node from top-level summaries
   */
  private async createRootNode(
    topNodes: DocumentNode[],
    courseContext: {
      courseName: string;
      courseCode: string;
    }
  ): Promise<DocumentNode> {
    // Create cluster from top nodes
    const centroid = this.computeCentroid(topNodes);

    const topCluster: DocumentCluster = {
      id: "root-cluster",
      members: topNodes,
      centroid,
      summary: "",
      coherenceScore: 0,
      metadata: {
        intraClusterSimilarity: 1.0,
        size: topNodes.length,
        level: topNodes[0].level,
      },
    };

    // Generate root summary
    const rootSummary = await this.summarizer.summarize(
      topCluster,
      courseContext
    );
    const coherence = await this.summarizer.validateCoherence(
      rootSummary,
      topCluster
    );

    // Embed summary
    const embedding = await this.embedder["embedText"](rootSummary);

    // Collect all material IDs
    const materialIds = topNodes.flatMap(n => n.materialIds);

    const root: DocumentNode = {
      id: "root",
      level: topNodes[0].level + 1,
      content: rootSummary,
      summary: rootSummary,
      embedding: {
        vector: embedding.vector,
        dimensions: embedding.vector.length,
      },
      children: topNodes,
      parent: null,
      materialIds,
      metadata: {
        title: `${courseContext.courseCode} - Complete Overview`,
        coherenceScore: coherence * 100,
        tokenCount: Math.ceil(rootSummary.length / 4),
        createdAt: new Date().toISOString(),
      },
    };

    // Link children to root
    for (const child of topNodes) {
      child.parent = root;
    }

    return root;
  }

  /**
   * Compute centroid of multiple nodes
   */
  private computeCentroid(nodes: DocumentNode[]): Embedding {
    const dim = nodes[0].embedding.dimensions;
    const centroid = new Array(dim).fill(0);

    for (const node of nodes) {
      for (let i = 0; i < dim; i++) {
        centroid[i] += node.embedding.vector[i];
      }
    }

    for (let i = 0; i < dim; i++) {
      centroid[i] /= nodes.length;
    }

    // Normalize
    const norm = Math.sqrt(centroid.reduce((sum, val) => sum + val * val, 0));
    for (let i = 0; i < dim; i++) {
      centroid[i] /= norm;
    }

    return {
      vector: centroid,
      dimensions: dim,
    };
  }
}
```

---

## 8. Storage Strategy

### 8.1 In-Memory Only (Phase 2)

- Store hierarchy in `Map<courseId, HierarchyTree>`
- Pre-compute during material indexing
- Rebuild on material changes
- No persistence (rebuild on page refresh)

### 8.2 Future: localStorage/IndexedDB (Phase 3)

```typescript
// Save to localStorage
const serialized = JSON.stringify(tree, (key, value) => {
  // Handle Map serialization
  if (value instanceof Map) {
    return { _type: "Map", entries: Array.from(value.entries()) };
  }
  return value;
});
localStorage.setItem(`hierarchy-${courseId}`, serialized);

// Load from localStorage
const data = localStorage.getItem(`hierarchy-${courseId}`);
if (data) {
  const tree = JSON.parse(data, (key, value) => {
    // Handle Map deserialization
    if (value && value._type === "Map") {
      return new Map(value.entries);
    }
    return value;
  });
}
```

---

## 9. Test Strategy

### 9.1 Unit Tests

**DocumentClusterer:**
- Test hierarchical clustering produces balanced clusters
- Test k-means clustering converges
- Test similarity metrics (cosine, euclidean)
- Test edge cases (1 doc, 2 docs, many docs)

**HierarchySummarizer:**
- Mock LLM responses, test summarization flow
- Test coherence validation
- Test extractive fallback
- Test batch summarization

**HierarchyTraverser:**
- Test top-down traversal finds relevant nodes
- Test bottom-up traversal includes ancestors
- Test hybrid combines both strategies
- Test deduplication logic

### 9.2 Integration Tests

**End-to-End:**
- Build hierarchy from 10 sample materials
- Verify 2-3 levels created
- Verify summaries are coherent (>0.7)
- Query hierarchy with sample questions
- Verify retrieval results include multi-level nodes

### 9.3 Performance Tests

**Construction:**
- Measure construction time for 10, 50, 100 docs
- Verify <10s for 50 docs
- Count LLM calls (should be ~10-15 for 50 docs)

**Query:**
- Measure traversal time for various strategies
- Verify <100ms per query
- Verify memory usage <10MB per course

---

## 10. Expected Outcomes

### 10.1 Quality Improvements

- **Coherence:** +20% on high-level questions ("explain binary search")
- **Coverage:** +15% on multi-topic questions (hierarchy provides context)
- **Precision:** +10% on vague queries (summaries clarify intent)

### 10.2 Performance

- **Construction:** <10s for 50 documents (one-time)
- **Query:** +50-100ms latency (traversal overhead)
- **Total:** <2s end-to-end (within budget)

### 10.3 Cost

- **Summary generation:** $0.001 per cluster Ã— 10 clusters = $0.01 per course (one-time)
- **Retrieval:** $0 (no LLM calls, embeddings only)
- **Cache savings:** High (summaries cached permanently)

---

## Summary

This RAPTOR implementation provides:

1. **Type-Safe Interfaces:** Complete TypeScript definitions with no `any` types
2. **Modular Architecture:** Separate clusterer, summarizer, traverser classes
3. **Multiple Strategies:** Hierarchical/k-means clustering, top-down/bottom-up/hybrid traversal
4. **Integration Ready:** Clean interfaces to existing retrieval system
5. **Performance Optimized:** In-memory storage, batched LLM calls, prompt caching
6. **Testable:** Clear separation of concerns, mockable dependencies

**Next Steps:** Implement classes in order, test incrementally, integrate with `HybridRetriever`.
